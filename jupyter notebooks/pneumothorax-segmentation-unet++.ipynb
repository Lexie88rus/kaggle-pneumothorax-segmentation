{"cells":[{"metadata":{},"cell_type":"markdown","source":"# PyTorch UNet Model for Pneumothorax Segmentation"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Imports\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\nimport pydicom\nimport random\n\n# import image manipulation\nfrom PIL import Image\n\n# import matplotlib for visualization\nfrom matplotlib.pyplot import imshow\nimport matplotlib.pyplot as plt\n\n# Import PyTorch\nimport torch\nfrom torch import nn\nfrom torch import optim\nfrom torch.optim import lr_scheduler\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms.functional as TF\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.autograd import Variable\n\nfrom skimage.morphology import binary_opening, disk, label\n\n# Import rle utils\nimport sys\nsys.path.insert(0, '../input/siim-acr-pneumothorax-segmentation')\nfrom mask_functions import rle2mask, mask2rle # import mask utilities\n\nfrom tqdm import tqdm_notebook","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install albumentations","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install torchcontrib","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchcontrib.optim import SWA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nfrom albumentations import (\n    Compose, HorizontalFlip, CLAHE, HueSaturationValue,\n    RandomBrightness, RandomContrast, RandomGamma,OneOf,\n    ToFloat, ShiftScaleRotate,GridDistortion, ElasticTransform, JpegCompression, HueSaturationValue,\n    RGBShift, RandomBrightness, RandomContrast, Blur, MotionBlur, MedianBlur, GaussNoise,CenterCrop,\n    IAAAdditiveGaussianNoise,GaussNoise,OpticalDistortion\n)\nfrom albumentations.pytorch import ToTensor","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataset Utility Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data loading utility\ndef load_data(datafilepath = '../input/siim-train-test/siim/', healthy_num = 2000):\n    '''\n    Function to load the dataset.\n    INPUT:\n        datafilepath - path to directory containing the dataset.\n    OUTPUT:\n        train_fns - train dataset\n        train_fns - test dataset\n        df_masks - pandas dataframe containing masks for train dataset\n    '''\n    # Load full training and test sets\n    train_fns = sorted(glob(datafilepath + 'dicom-images-train/*/*/*.dcm'))\n    test_fns = sorted(glob(datafilepath + 'dicom-images-test/*/*/*.dcm'))\n    # Load csv masks\n    df_masks = pd.read_csv(datafilepath + 'train-rle.csv', index_col='ImageId')\n    # create a list of filenames with images to use\n    \n    counter = 0\n    files_list = []\n    for fname in train_fns:\n        try:\n            if '-1' in df_masks.loc[fname.split('/')[-1][:-4],' EncodedPixels']:\n                if counter <= healthy_num:\n                    files_list.append(fname)\n                    counter += 1\n            else:\n                files_list.append(fname)\n        except:\n            pass\n\n    return train_fns, test_fns, df_masks, files_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize(arr):\n    \"\"\"\n    Function performs the linear normalizarion of the array.\n    https://stackoverflow.com/questions/7422204/intensity-normalization-of-image-using-pythonpil-speed-issues\n    http://en.wikipedia.org/wiki/Normalization_%28image_processing%29\n    INPUT:\n        arr - orginal numpy array\n    OUTPUT:\n        arr - normalized numpy array\n    \"\"\"\n    arr = arr.astype('float')\n    # Do not touch the alpha channel\n    for i in range(3):\n        minval = arr[...,i].min()\n        maxval = arr[...,i].max()\n        if minval != maxval:\n            arr[...,i] -= minval\n            arr[...,i] *= (255.0/(maxval-minval))\n    return arr\n\ndef normalize_image(img):\n    \"\"\"\n    Function performs the normalization of the image.\n    https://stackoverflow.com/questions/7422204/intensity-normalization-of-image-using-pythonpil-speed-issues\n    INPUT:\n        image - PIL image to be normalized\n    OUTPUT:\n        new_img - PIL image normalized\n    \"\"\"\n    arr = np.array(img)\n    new_img = Image.fromarray(normalize(arr).astype('uint8'),'RGB')\n    return new_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the dataset\nclass PneumothoraxDataset(Dataset):\n    '''\n    The dataset for pneumothorax segmentation.\n    '''\n\n    def __init__(self, fns, df_masks, files_list, transform=True, size = (224, 224), mode = 'train'):\n        '''\n        INPUT:\n            fns - glob containing the images\n            df_masks - dataframe containing image masks\n            transform (optional) - enable transforms for the images\n        '''\n        self.labels_frame = df_masks\n        self.fns = fns\n        self.transform = transform\n        self.size = size\n        self.transforms_mask = transforms.Compose([transforms.Resize(self.size), transforms.ToTensor()])\n        self.transforms_image = transforms.Compose([transforms.Resize(self.size), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n        self.alb_transforms = Compose([HorizontalFlip(p=0.5),\n                                             OneOf([RandomContrast(),\n                                                    RandomGamma(),\n                                                    RandomBrightness(),], p=0.3),\n                                             OneOf([ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n                                                    GridDistortion(),\n                                                    OpticalDistortion(distort_limit=2, shift_limit=0.5),], p=0.3)])\n        self.mode = mode\n        self.files_list = files_list\n\n    def __len__(self):\n        if (self.mode == 'validation'):\n            return len(self.fns)\n        else:\n            return len(self.files_list)\n\n    def __getitem__(self, idx):\n        '''\n        Function to get items from dataset by idx.\n        INPUT:\n            idx - id of the image in the dataset\n        '''\n        # image height and width\n        im_height = 1024\n        im_width = 1024\n        # image channels\n        im_chan = 1\n\n        # get train image and mask\n        np_image = np.zeros((im_height, im_width, im_chan), dtype=np.uint8)\n        np_mask = np.zeros((im_height, im_width, 1), dtype=np.bool)\n        \n        # if validation then return filename instead of mask\n        if self.mode == 'validation':\n            # read dcm file with image\n            dataset = pydicom.read_file(self.fns[idx])\n            np_image = np.expand_dims(dataset.pixel_array, axis=2)\n        \n            image = Image.fromarray(np_image.reshape(im_height, im_width) , 'L')\n            image = image.convert('RGB')\n            \n            image = self.transforms_image(image)\n            return [image, self.fns[idx].split('/')[-1][:-4]]\n        \n        # read dcm file with image\n        dataset = pydicom.read_file(self.files_list[idx])\n        np_image = np.expand_dims(dataset.pixel_array, axis=2)\n\n        # load mask\n        try:\n            # no pneumothorax\n            if '-1' in self.labels_frame.loc[self.files_list[idx].split('/')[-1][:-4],' EncodedPixels']:\n                np_mask = np.zeros((im_height, im_width, 1), dtype=np.bool)\n            else:\n                # there is pneumothorax\n                if type(self.labels_frame.loc[self.files_list[idx].split('/')[-1][:-4],' EncodedPixels']) == str:\n                    np_mask = np.expand_dims(rle2mask(self.labels_frame.loc[self.files_list[idx].split('/')[-1][:-4],' EncodedPixels'], im_height, im_width), axis=2)\n                else:\n                    np_mask = np.zeros((1024, 1024, 1))\n                    for x in self.labels_frame.loc[self.files_list[idx].split('/')[-1][:-4],' EncodedPixels']:\n                        np_mask =  np_mask + np.expand_dims(rle2mask(x, 1024, 1024), axis=2)\n        except KeyError:\n            # couldn't find mask in dataframe\n            np_mask = np.zeros((im_height, im_width, 1), dtype=np.bool) # Assume missing masks are empty masks.\n\n        # convert to PIL\n        image = Image.fromarray(np_image.reshape(im_height, im_width) , 'L')\n        image = image.convert('RGB')\n        \n        np_mask = np.transpose(np_mask)\n        mask = Image.fromarray(np_mask.reshape(im_height, im_width).astype(np.uint8) , 'L')\n        \n        if self.transform:\n            augmented = self.alb_transforms(image=np.array(image), mask=np.array(mask))\n            image = Image.fromarray(augmented['image'], 'RGB')\n            \n            mask = Image.fromarray(augmented['mask'], 'L')\n        \n        # apply required transforms normalization, reshape and convert to tensor\n        #image = normalize_image(image)\n        image = self.transforms_image(image)\n        mask = self.transforms_mask(mask)\n        \n        # convert to tensor and clip mask\n        mask = torch.from_numpy(np.array(mask, dtype=np.int64))\n        mask = np.clip(mask, 0, 1)\n\n        return image, mask","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training Utilities"},{"metadata":{},"cell_type":"markdown","source":"U-Net Model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://github.com/4uiiurz1/pytorch-nested-unet/blob/master/metrics.py\ndef mean_iou(y_true_in, y_pred_in, print_table=False):\n    if True: #not np.sum(y_true_in.flatten()) == 0:\n        labels = y_true_in\n        y_pred = y_pred_in\n\n        true_objects = 2\n        pred_objects = 2\n\n        intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n\n        # Compute areas (needed for finding the union between all objects)\n        area_true = np.histogram(labels, bins = true_objects)[0]\n        area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n        area_true = np.expand_dims(area_true, -1)\n        area_pred = np.expand_dims(area_pred, 0)\n\n        # Compute union\n        union = area_true + area_pred - intersection\n\n        # Exclude background from the analysis\n        intersection = intersection[1:,1:]\n        union = union[1:,1:]\n        union[union == 0] = 1e-9\n\n        # Compute the intersection over union\n        iou = intersection / union\n\n        # Precision helper function\n        def precision_at(threshold, iou):\n            matches = iou > threshold\n            true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n            false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n            false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n            tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n            return tp, fp, fn\n\n        # Loop over IoU thresholds\n        prec = []\n        if print_table:\n            print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n        for t in np.arange(0.5, 1.0, 0.05):\n            tp, fp, fn = precision_at(t, iou)\n            if (tp + fp + fn) > 0:\n                p = tp / (tp + fp + fn)\n            else:\n                p = 0\n            if print_table:\n                print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n            prec.append(p)\n\n        if print_table:\n            print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n        return np.mean(prec)\n\n    else:\n        if np.sum(y_pred_in.flatten()) == 0:\n            return 1\n        else:\n            return 0\n\n\ndef batch_iou(output, target):\n    output = torch.sigmoid(output).data.cpu().numpy() > 0.5\n    target = (target.data.cpu().numpy() > 0.5).astype('int')\n    output = output[:,0,:,:]\n    target = target[:,0,:,:]\n\n    ious = []\n    for i in range(output.shape[0]):\n        ious.append(mean_iou(output[i], target[i]))\n\n    return np.mean(ious)\n\n\ndef mean_iou(output, target):\n    smooth = 1e-5\n\n    output = torch.sigmoid(output).data.cpu().numpy()\n    target = target.data.cpu().numpy()\n    ious = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        output_ = output > t\n        target_ = target > t\n        intersection = (output_ & target_).sum()\n        union = (output_ | target_).sum()\n        iou = (intersection + smooth) / (union + smooth)\n        ious.append(iou)\n\n    return np.mean(ious)\n\n\ndef iou_score(output, target):\n    smooth = 1e-5\n\n    if torch.is_tensor(output):\n        output = torch.sigmoid(output).data.cpu().numpy()\n    if torch.is_tensor(target):\n        target = target.data.cpu().numpy()\n    output_ = output > 0.5\n    target_ = target > 0.5\n    intersection = (output_ & target_).sum()\n    union = (output_ | target_).sum()\n\n    return (intersection + smooth) / (union + smooth)\n\n\ndef dice_coef(output, target):\n    smooth = 1e-5\n\n    output = torch.sigmoid(output).view(-1).data.cpu().numpy()\n    target = target.view(-1).data.cpu().numpy()\n    intersection = (output * target).sum()\n\n    return (2. * intersection + smooth) / \\\n        (output.sum() + target.sum() + smooth)\n\n\ndef accuracy(output, target):\n    output = torch.sigmoid(output).view(-1).data.cpu().numpy()\n    output = (np.round(output)).astype('int')\n    target = target.view(-1).data.cpu().numpy()\n    target = (np.round(target)).astype('int')\n    (output == target).sum()\n\n    return (output == target).sum() / len(output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\ndef get_iou_vector(A, B):    \n    batch_size = A.shape[0]\n    metric = 0.0\n        \n    for batch in range(batch_size):\n        p, t = A[batch].reshape(224,224), B[batch]\n        true = np.sum(t)\n        pred = np.sum(p)\n        \n        # deal with empty mask first\n        if true == 0:\n            metric += (pred == 0)\n            continue\n        \n        # non empty mask case.  Union is never empty \n        # hence it is safe to divide by its number of pixels\n        \n        intersection = np.sum(t * p)\n        union = true + pred - intersection\n        iou = intersection / union\n        \n        # iou metric is a stepwise approximation of the real iou over 0.5\n        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n              \n        metric += iou\n        \n    # teake the average over all images in batch\n    metric /= batch_size\n    return metric\n\ndef my_iou_metric(pred, label):\n    pred = torch.sigmoid(pred)\n    return get_iou_vector((pred > 0.5).float().detach().cpu().numpy(), label.detach().cpu().numpy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BCEDiceLoss(nn.Module):\n    def __init__(self):\n        super(BCEDiceLoss, self).__init__()\n\n    def forward(self, input, target):\n        bce = F.binary_cross_entropy_with_logits(input, target)\n        smooth = 1e-5\n        input = torch.sigmoid(input)\n        num = target.size(0)\n        input = input.view(num, -1)\n        target = target.view(num, -1)\n        intersection = (input * target)\n        dice = (2. * intersection.sum(1) + smooth) / (input.sum(1) + target.sum(1) + smooth)\n        dice = 1 - dice.sum() / num\n        return 0.5 * bce + dice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class VGGBlock(nn.Module):\n    def __init__(self, in_channels, middle_channels, out_channels, act_func=nn.ReLU(inplace=True)):\n        super(VGGBlock, self).__init__()\n        self.act_func = act_func\n        self.conv1 = nn.Conv2d(in_channels, middle_channels, 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(middle_channels)\n        self.conv2 = nn.Conv2d(middle_channels, out_channels, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.act_func(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.act_func(out)\n\n        return out\n\n\nclass UNet(nn.Module):\n    def __init__(self, args):\n        super().__init__()\n\n        self.args = args\n\n        nb_filter = [32, 64, 128, 256, 512]\n\n        self.pool = nn.MaxPool2d(2, 2)\n        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n\n        self.conv0_0 = VGGBlock(args['input_channels'], nb_filter[0], nb_filter[0])\n        self.conv1_0 = VGGBlock(nb_filter[0], nb_filter[1], nb_filter[1])\n        self.conv2_0 = VGGBlock(nb_filter[1], nb_filter[2], nb_filter[2])\n        self.conv3_0 = VGGBlock(nb_filter[2], nb_filter[3], nb_filter[3])\n        self.conv4_0 = VGGBlock(nb_filter[3], nb_filter[4], nb_filter[4])\n\n        self.conv3_1 = VGGBlock(nb_filter[3]+nb_filter[4], nb_filter[3], nb_filter[3])\n        self.conv2_2 = VGGBlock(nb_filter[2]+nb_filter[3], nb_filter[2], nb_filter[2])\n        self.conv1_3 = VGGBlock(nb_filter[1]+nb_filter[2], nb_filter[1], nb_filter[1])\n        self.conv0_4 = VGGBlock(nb_filter[0]+nb_filter[1], nb_filter[0], nb_filter[0])\n\n        self.final = nn.Conv2d(nb_filter[0], 1, kernel_size=1)\n\n\n    def forward(self, input):\n        x0_0 = self.conv0_0(input)\n        x1_0 = self.conv1_0(self.pool(x0_0))\n        x2_0 = self.conv2_0(self.pool(x1_0))\n        x3_0 = self.conv3_0(self.pool(x2_0))\n        x4_0 = self.conv4_0(self.pool(x3_0))\n\n        x3_1 = self.conv3_1(torch.cat([x3_0, self.up(x4_0)], 1))\n        x2_2 = self.conv2_2(torch.cat([x2_0, self.up(x3_1)], 1))\n        x1_3 = self.conv1_3(torch.cat([x1_0, self.up(x2_2)], 1))\n        x0_4 = self.conv0_4(torch.cat([x0_0, self.up(x1_3)], 1))\n\n        output = self.final(x0_4)\n        return output\n\n\nclass NestedUNet(nn.Module):\n    def __init__(self, args):\n        super().__init__()\n\n        self.args = args\n\n        nb_filter = [32, 64, 128, 256, 512]\n\n        self.pool = nn.MaxPool2d(2, 2)\n        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n\n        self.conv0_0 = VGGBlock(args['input_channels'], nb_filter[0], nb_filter[0])\n        self.conv1_0 = VGGBlock(nb_filter[0], nb_filter[1], nb_filter[1])\n        self.conv2_0 = VGGBlock(nb_filter[1], nb_filter[2], nb_filter[2])\n        self.conv3_0 = VGGBlock(nb_filter[2], nb_filter[3], nb_filter[3])\n        self.conv4_0 = VGGBlock(nb_filter[3], nb_filter[4], nb_filter[4])\n\n        self.conv0_1 = VGGBlock(nb_filter[0]+nb_filter[1], nb_filter[0], nb_filter[0])\n        self.conv1_1 = VGGBlock(nb_filter[1]+nb_filter[2], nb_filter[1], nb_filter[1])\n        self.conv2_1 = VGGBlock(nb_filter[2]+nb_filter[3], nb_filter[2], nb_filter[2])\n        self.conv3_1 = VGGBlock(nb_filter[3]+nb_filter[4], nb_filter[3], nb_filter[3])\n\n        self.conv0_2 = VGGBlock(nb_filter[0]*2+nb_filter[1], nb_filter[0], nb_filter[0])\n        self.conv1_2 = VGGBlock(nb_filter[1]*2+nb_filter[2], nb_filter[1], nb_filter[1])\n        self.conv2_2 = VGGBlock(nb_filter[2]*2+nb_filter[3], nb_filter[2], nb_filter[2])\n\n        self.conv0_3 = VGGBlock(nb_filter[0]*3+nb_filter[1], nb_filter[0], nb_filter[0])\n        self.conv1_3 = VGGBlock(nb_filter[1]*3+nb_filter[2], nb_filter[1], nb_filter[1])\n\n        self.conv0_4 = VGGBlock(nb_filter[0]*4+nb_filter[1], nb_filter[0], nb_filter[0])\n\n        if self.args['deepsupervision']:\n            self.final1 = nn.Conv2d(nb_filter[0], 1, kernel_size=1)\n            self.final2 = nn.Conv2d(nb_filter[0], 1, kernel_size=1)\n            self.final3 = nn.Conv2d(nb_filter[0], 1, kernel_size=1)\n            self.final4 = nn.Conv2d(nb_filter[0], 1, kernel_size=1)\n        else:\n            self.final = nn.Conv2d(nb_filter[0], 1, kernel_size=1)\n\n\n    def forward(self, input):\n        x0_0 = self.conv0_0(input)\n        x1_0 = self.conv1_0(self.pool(x0_0))\n        x0_1 = self.conv0_1(torch.cat([x0_0, self.up(x1_0)], 1))\n\n        x2_0 = self.conv2_0(self.pool(x1_0))\n        x1_1 = self.conv1_1(torch.cat([x1_0, self.up(x2_0)], 1))\n        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.up(x1_1)], 1))\n\n        x3_0 = self.conv3_0(self.pool(x2_0))\n        x2_1 = self.conv2_1(torch.cat([x2_0, self.up(x3_0)], 1))\n        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.up(x2_1)], 1))\n        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.up(x1_2)], 1))\n\n        x4_0 = self.conv4_0(self.pool(x3_0))\n        x3_1 = self.conv3_1(torch.cat([x3_0, self.up(x4_0)], 1))\n        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.up(x3_1)], 1))\n        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.up(x2_2)], 1))\n        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.up(x1_3)], 1))\n\n        if self.args['deepsupervision']:\n            output1 = self.final1(x0_1)\n            output2 = self.final2(x0_2)\n            output3 = self.final3(x0_3)\n            output4 = self.final4(x0_4)\n            return [output1, output2, output3, output4]\n\n        else:\n            output = self.final(x0_4)\n            return output","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model, device, trainloader, testloader, optimizer, epochs):\n    model.to(device)\n    steps = 0\n    running_loss = 0\n    running_iou = 0\n    print_every = 100\n    \n    # initialize stochastic weight averaging\n    opt = SWA(optimizer)\n    \n    #initialize loss function\n    bce_dice_loss = BCEDiceLoss()\n    \n    # learning rate cosine annealing\n    scheduler = lr_scheduler.CosineAnnealingLR(optimizer, len(trainloader), eta_min=0.0000001)\n\n    for epoch in range(epochs):\n        scheduler.step()\n        \n        for inputs, labels in trainloader:\n\n            steps += 1\n            # Move input and label tensors to the default device\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            opt.zero_grad()\n\n            outputs = model.forward(inputs)\n            loss = bce_dice_loss(outputs, labels.float())\n            loss.backward()\n            opt.step()\n\n            running_loss += loss\n            running_iou += iou_score(outputs, labels.float())\n            #running_iou += my_iou_metric(outputs, labels.float())\n\n            if steps % print_every == 0:\n                test_loss = 0\n                iou = 0\n                model.eval()\n                with torch.no_grad():\n                    for inputs, labels in testloader:\n                        inputs, labels = inputs.to(device), labels.to(device)\n                        outputs = model.forward(inputs)\n                        \n                        test_loss += bce_dice_loss(outputs, labels.float())\n                        \n                        iou += iou_score(outputs, labels.float())\n                        #iou += my_iou_metric(outputs, labels.float())\n\n                print(f\"Epoch {epoch+1}/{epochs}.. \"\n                      f\"Train loss: {running_loss/print_every:.3f}.. \"\n                      f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n                      f\"Train IOU: {running_iou/print_every:.3f}.. \"\n                      f\"Test IOU: {iou/len(testloader):.3f}.. \")\n \n                running_loss = 0\n                running_iou = 0\n                   \n                model.train()\n                opt.update_swa()\n                \n    opt.swap_swa_sgd()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load data\nprint('Loading data: \\n')\ntrain_fns, test_fns, df_masks, files_list = load_data()\n\n# Training presets\nbatch_size = 16\nepochs = 80\nlearning_rate = 0.0001\ntest_split = .1\n\noriginal_size = 1024\nwidth = 224\nheight = 224\n\n# Create dataset and data loader\nprint('Preparing the dataset: \\n')\ntrain_ds = PneumothoraxDataset(train_fns, df_masks, files_list, transform=True, size = (height, width), mode = 'train')\n\n# Creating data indices for training and validation splits:\ndataset_size = len(train_ds)\nindices = list(range(dataset_size))\nsplit = int(np.floor(test_split * dataset_size))\nnp.random.seed(42)\nnp.random.shuffle(indices)\ntrain_indices, test_indices = indices[split:], indices[:split]\n\ntrain_sampler = SubsetRandomSampler(train_indices)\ntest_sampler = SubsetRandomSampler(test_indices)\n\ntrainloader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, sampler=train_sampler, num_workers=4)\ntestloader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, sampler=test_sampler, num_workers=4)\n\nvalid_ds = PneumothoraxDataset(test_fns, None, None, transform=False, size = (height, width), mode = 'validation')\nvalidloader = DataLoader(valid_ds, batch_size=8, shuffle=False, num_workers=1)\n\ntorch.cuda.empty_cache()\n\n# Prepare for training: initialize model, loss function, optimizer\nargs = {'input_channels': 3, 'deepsupervision' : False}\nmodel = NestedUNet(args)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n# Setup device for training\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n\n# Train the model\nprint('Train the model: \\n')\n\ntrain_stats_df = pd.DataFrame(columns = ['Epoch','Train loss','Test loss'])\ntrain(model, device, trainloader, testloader, optimizer, epochs)\n\n# Save the model\n#print('Save the model: \\n')\n#filepath = 'simple_unet.pth'\n#checkpoint = {'state_dict': model.state_dict()}\n#torch.save(checkpoint, filepath)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = {'ImageId': [], 'EncodedPixels': []}\n\nmodel.eval()\ntorch.cuda.empty_cache()\n\nfor X, fns in tqdm_notebook(validloader):\n    X = Variable(X).cuda()\n    output = model(X)\n    \n    for i, fname in enumerate(fns):\n        mask = torch.sigmoid(output[i].reshape(224,224)).data.cpu().numpy()\n        mask = binary_opening(mask > 0.9, disk(2))\n        \n        im = Image.fromarray(((mask)*255).astype(np.uint8)).resize((original_size,original_size))\n        im = np.transpose(np.asarray(im))\n        \n        submission['EncodedPixels'].append(mask2rle(im, original_size, original_size))\n        submission['ImageId'].append(fname)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.DataFrame(submission, columns=['ImageId', 'EncodedPixels'])\nsubmission_df.loc[submission_df.EncodedPixels=='', 'EncodedPixels'] = '-1'\nsubmission_df.to_csv('submission09.csv', index=False)\nsubmission_df.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.cuda.empty_cache()\n\nfor X, fns in tqdm_notebook(validloader):\n    X = Variable(X).cuda()\n    output = model(X)\n    \n    for i, fname in enumerate(fns):\n        mask = torch.sigmoid(output[i].reshape(224,224)).data.cpu().numpy()\n        mask = binary_opening(mask > 0.5, disk(2))\n        \n        im = Image.fromarray(((mask)*255).astype(np.uint8)).resize((original_size,original_size))\n        im = np.transpose(np.asarray(im))\n        \n        submission['EncodedPixels'].append(mask2rle(im, original_size, original_size))\n        submission['ImageId'].append(fname)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.DataFrame(submission, columns=['ImageId', 'EncodedPixels'])\nsubmission_df.loc[submission_df.EncodedPixels=='', 'EncodedPixels'] = '-1'\nsubmission_df.to_csv('submission05.csv', index=False)\nsubmission_df.sample(10)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}