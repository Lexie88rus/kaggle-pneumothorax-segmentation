{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch UNet Model for Pneumothorax Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import pydicom\n",
    "import random\n",
    "\n",
    "# import image manipulation\n",
    "from PIL import Image\n",
    "\n",
    "# import matplotlib for visualization\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from skimage.morphology import binary_opening, disk, label\n",
    "\n",
    "# Import rle utils\n",
    "import sys\n",
    "sys.path.insert(0, '../input/siim-acr-pneumothorax-segmentation')\n",
    "from mask_functions import rle2mask, mask2rle # import mask utilities\n",
    "\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Augmentor\r\n",
      "  Downloading https://files.pythonhosted.org/packages/c9/d2/05184ea0e0c12f85d68da7b96fd6c05f294862143758314fcb2a9951d338/Augmentor-0.2.6-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: Pillow>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from Augmentor) (6.0.0)\r\n",
      "Requirement already satisfied: tqdm>=4.9.0 in /opt/conda/lib/python3.6/site-packages (from Augmentor) (4.32.1)\r\n",
      "Requirement already satisfied: future>=0.16.0 in /opt/conda/lib/python3.6/site-packages (from Augmentor) (0.17.1)\r\n",
      "Requirement already satisfied: numpy>=1.11.0 in /opt/conda/lib/python3.6/site-packages (from Augmentor) (1.16.4)\r\n",
      "Installing collected packages: Augmentor\r\n",
      "Successfully installed Augmentor-0.2.6\r\n"
     ]
    }
   ],
   "source": [
    "! pip install Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Augmentor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading utility\n",
    "def load_data(datafilepath = '../input/siim-train-test/siim/', healthy_num = 2000):\n",
    "    '''\n",
    "    Function to load the dataset.\n",
    "    INPUT:\n",
    "        datafilepath - path to directory containing the dataset.\n",
    "    OUTPUT:\n",
    "        train_fns - train dataset\n",
    "        train_fns - test dataset\n",
    "        df_masks - pandas dataframe containing masks for train dataset\n",
    "    '''\n",
    "    # Load full training and test sets\n",
    "    train_fns = sorted(glob(datafilepath + 'dicom-images-train/*/*/*.dcm'))\n",
    "    test_fns = sorted(glob(datafilepath + 'dicom-images-test/*/*/*.dcm'))\n",
    "    # Load csv masks\n",
    "    df_masks = pd.read_csv(datafilepath + 'train-rle.csv', index_col='ImageId')\n",
    "    # create a list of filenames with images to use\n",
    "    \n",
    "    counter = 0\n",
    "    files_list = []\n",
    "    for fname in train_fns:\n",
    "        try:\n",
    "            if '-1' in df_masks.loc[fname.split('/')[-1][:-4],' EncodedPixels']:\n",
    "                if counter <= healthy_num:\n",
    "                    files_list.append(fname)\n",
    "                    counter += 1\n",
    "            else:\n",
    "                files_list.append(fname)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return train_fns, test_fns, df_masks, files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(arr):\n",
    "    \"\"\"\n",
    "    Function performs the linear normalizarion of the array.\n",
    "    https://stackoverflow.com/questions/7422204/intensity-normalization-of-image-using-pythonpil-speed-issues\n",
    "    http://en.wikipedia.org/wiki/Normalization_%28image_processing%29\n",
    "    INPUT:\n",
    "        arr - orginal numpy array\n",
    "    OUTPUT:\n",
    "        arr - normalized numpy array\n",
    "    \"\"\"\n",
    "    arr = arr.astype('float')\n",
    "    # Do not touch the alpha channel\n",
    "    for i in range(1):\n",
    "        minval = arr[...,i].min()\n",
    "        maxval = arr[...,i].max()\n",
    "        if minval != maxval:\n",
    "            arr[...,i] -= minval\n",
    "            arr[...,i] *= (255.0/(maxval-minval))\n",
    "    return arr\n",
    "\n",
    "def normalize_image(img):\n",
    "    \"\"\"\n",
    "    Function performs the normalization of the image.\n",
    "    https://stackoverflow.com/questions/7422204/intensity-normalization-of-image-using-pythonpil-speed-issues\n",
    "    INPUT:\n",
    "        image - PIL image to be normalized\n",
    "    OUTPUT:\n",
    "        new_img - PIL image normalized\n",
    "    \"\"\"\n",
    "    arr = np.array(img)\n",
    "    new_img = Image.fromarray(normalize(arr).astype('uint8'),'L')\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset\n",
    "class PneumothoraxDataset(Dataset):\n",
    "    '''\n",
    "    The dataset for pneumothorax segmentation.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, fns, df_masks, files_list, transform=True, size = (224, 224), mode = 'train'):\n",
    "        '''\n",
    "        INPUT:\n",
    "            fns - glob containing the images\n",
    "            df_masks - dataframe containing image masks\n",
    "            transform (optional) - enable transforms for the images\n",
    "        '''\n",
    "        self.labels_frame = df_masks\n",
    "        self.fns = fns\n",
    "        self.transform = transform\n",
    "        self.size = size\n",
    "        self.transforms = transforms.Compose([transforms.Resize(self.size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
    "        self.mode = mode\n",
    "        self.files_list = files_list\n",
    "\n",
    "    def __len__(self):\n",
    "        if (self.mode == 'validation'):\n",
    "            return len(self.fns)\n",
    "        else:\n",
    "            return len(self.files_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        Function to get items from dataset by idx.\n",
    "        INPUT:\n",
    "            idx - id of the image in the dataset\n",
    "        '''\n",
    "        # image height and width\n",
    "        im_height = 1024\n",
    "        im_width = 1024\n",
    "        # image channels\n",
    "        im_chan = 1\n",
    "\n",
    "        # get train image and mask\n",
    "        np_image = np.zeros((im_height, im_width, im_chan), dtype=np.uint8)\n",
    "        np_mask = np.zeros((im_height, im_width, 1), dtype=np.bool)\n",
    "        \n",
    "        # if validation then return filename instead of mask\n",
    "        if self.mode == 'validation':\n",
    "            # read dcm file with image\n",
    "            dataset = pydicom.read_file(self.fns[idx])\n",
    "            np_image = np.expand_dims(dataset.pixel_array, axis=2)\n",
    "        \n",
    "            image = Image.fromarray(np_image.reshape(im_height, im_width) , 'L')\n",
    "            image = self.transforms(image)\n",
    "            return [image, self.fns[idx].split('/')[-1][:-4]]\n",
    "        \n",
    "        # read dcm file with image\n",
    "        dataset = pydicom.read_file(self.files_list[idx])\n",
    "        np_image = np.expand_dims(dataset.pixel_array, axis=2)\n",
    "\n",
    "        # load mask\n",
    "        try:\n",
    "            # no pneumothorax\n",
    "            if '-1' in self.labels_frame.loc[self.files_list[idx].split('/')[-1][:-4],' EncodedPixels']:\n",
    "                np_mask = np.zeros((im_height, im_width, 1), dtype=np.bool)\n",
    "            else:\n",
    "                # there is pneumothorax\n",
    "                if type(self.labels_frame.loc[self.files_list[idx].split('/')[-1][:-4],' EncodedPixels']) == str:\n",
    "                    np_mask = np.expand_dims(rle2mask(self.labels_frame.loc[self.files_list[idx].split('/')[-1][:-4],' EncodedPixels'], im_height, im_width), axis=2)\n",
    "                else:\n",
    "                    np_mask = np.zeros((1024, 1024, 1))\n",
    "                    for x in self.labels_frame.loc[self.files_list[idx].split('/')[-1][:-4],' EncodedPixels']:\n",
    "                        np_mask =  np_mask + np.expand_dims(rle2mask(x, 1024, 1024), axis=2)\n",
    "        except KeyError:\n",
    "            # couldn't find mask in dataframe\n",
    "            np_mask = np.zeros((im_height, im_width, 1), dtype=np.bool) # Assume missing masks are empty masks.\n",
    "\n",
    "        # convert to PIL\n",
    "        image = Image.fromarray(np_image.reshape(im_height, im_width) , 'L')\n",
    "        \n",
    "        np_mask = np.transpose(np_mask)\n",
    "        mask = Image.fromarray(np_mask.reshape(im_height, im_width).astype(np.uint8) , 'L')\n",
    "        \n",
    "        if self.transform:\n",
    "            p = Augmentor.DataPipeline([[np.array(image), np.array(mask)]])\n",
    "            p.rotate(0.5, max_left_rotation=3, max_right_rotation=3)\n",
    "            p.zoom_random(probability=0.3, percentage_area=0.955)\n",
    "            images_aug = p.sample(1)\n",
    "\n",
    "            image = Image.fromarray(images_aug[0][0].reshape(im_height, im_width).astype(np.uint8) , 'L')\n",
    "            mask = Image.fromarray(images_aug[0][1].reshape(im_height, im_width).astype(np.uint8) , 'L')\n",
    "\n",
    "            # apply random horizontal flip\n",
    "            flip = random.uniform(0, 1)\n",
    "            if (flip > 0.5):\n",
    "                image = TF.hflip(image)\n",
    "                mask = TF.hflip(mask)\n",
    "        \n",
    "        # apply required transforms normalization, reshape and convert to tensor\n",
    "        image = normalize_image(image)\n",
    "        image = self.transforms(image)\n",
    "        mask = self.transforms(mask)\n",
    "        \n",
    "        # convert to tensor and clip mask\n",
    "        mask = torch.from_numpy(np.array(mask, dtype=np.int64))\n",
    "        mask = np.clip(mask, 0, 1)\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U-Net Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "        \n",
    "    for batch in range(batch_size):\n",
    "        p, t = A[batch].reshape(224,224), B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        \n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metric is a stepwise approximation of the real iou over 0.5\n",
    "        #iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "              \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "def my_iou_metric(pred, label):\n",
    "    return get_iou_vector((pred > 0.5).float().detach().cpu().numpy(), label.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_pred, y_true):\n",
    "    y_true_f = y_true.view(-1)\n",
    "    y_pred = y_pred.float()\n",
    "    y_pred_f = (y_pred.view(-1) >= 0.5).float()\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * torch.sum(intersection) / (torch.sum(y_true_f) + torch.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_pred, y_true):\n",
    "    smooth = 1.\n",
    "    y_true_f = y_true.view(-1)\n",
    "    y_pred_f = y_pred.view(-1)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * torch.sum(intersection) + smooth) / (torch.sum(y_true_f) + torch.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "def bce_dice_loss(y_pred, y_true):\n",
    "    criterion = nn.BCELoss()\n",
    "    return criterion(y_pred.reshape(-1,224,224), y_true) + dice_loss(y_pred.reshape(-1,224,224), y_true)\n",
    "\n",
    "def bce_logdice_loss(y_pred, y_true):\n",
    "    criterion = nn.BCELoss()\n",
    "    return criterion(y_pred.reshape(-1,224,224), y_true) - torch.log(1. - dice_loss(y_pred.reshape(-1,224,224), y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/witwitchayakarn/u-net-with-pytorch\n",
    "\n",
    "def conv1x1(in_channels, out_channels, groups=1):\n",
    "    return nn.Conv2d(in_channels,\n",
    "                     out_channels,\n",
    "                     kernel_size=1,\n",
    "                     groups=groups,\n",
    "                     stride=1)\n",
    "\n",
    "def conv3x3(in_channels, out_channels, stride=1, padding=1, bias=True, groups=1):\n",
    "    return nn.Conv2d(in_channels,\n",
    "                     out_channels,\n",
    "                     kernel_size=3,\n",
    "                     stride=stride,\n",
    "                     padding=padding,\n",
    "                     bias=bias,\n",
    "                     groups=groups)\n",
    "\n",
    "def upconv2x2(in_channels, out_channels, mode='transpose'):\n",
    "    if mode == 'transpose':\n",
    "        return nn.ConvTranspose2d(in_channels,\n",
    "                                  out_channels,\n",
    "                                  kernel_size=2,\n",
    "                                  stride=2)\n",
    "    else:\n",
    "        return nn.Sequential(\n",
    "            nn.Upsample(mode='bilinear', scale_factor=2),\n",
    "            conv1x1(in_channels, out_channels))\n",
    "    \n",
    "class DownConv(nn.Module):\n",
    "    \"\"\"\n",
    "    A helper Module that performs 2 convolutions and 1 MaxPool.\n",
    "    A ReLU activation follows each convolution.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, pooling=True):\n",
    "        super(DownConv, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.pooling = pooling\n",
    "\n",
    "        self.conv1 = conv3x3(self.in_channels, self.out_channels)\n",
    "        self.conv2 = conv3x3(self.out_channels, self.out_channels)\n",
    "\n",
    "        if self.pooling:\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        before_pool = x\n",
    "        if self.pooling:\n",
    "            x = self.pool(x)\n",
    "        return x, before_pool\n",
    "\n",
    "class UpConv(nn.Module):\n",
    "    \"\"\"\n",
    "    A helper Module that performs 2 convolutions and 1 UpConvolution.\n",
    "    A ReLU activation follows each convolution.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 merge_mode='concat',\n",
    "                 up_mode='transpose'):\n",
    "        super(UpConv, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.merge_mode = merge_mode\n",
    "        self.up_mode = up_mode\n",
    "\n",
    "        self.upconv = upconv2x2(self.in_channels,\n",
    "                                self.out_channels,\n",
    "                                mode=self.up_mode)\n",
    "\n",
    "        if self.merge_mode == 'concat':\n",
    "            self.conv1 = conv3x3(2*self.out_channels,\n",
    "                                 self.out_channels)\n",
    "        else:\n",
    "            # num of input channels to conv2 is same\n",
    "            self.conv1 = conv3x3(self.out_channels, self.out_channels)\n",
    "\n",
    "        self.conv2 = conv3x3(self.out_channels, self.out_channels)\n",
    "\n",
    "    def forward(self, from_down, from_up):\n",
    "        \"\"\" Forward pass\n",
    "        Arguments:\n",
    "            from_down: tensor from the encoder pathway\n",
    "            from_up: upconv'd tensor from the decoder pathway\n",
    "        \"\"\"\n",
    "        from_up = self.upconv(from_up)\n",
    "        if self.merge_mode == 'concat':\n",
    "            x = torch.cat((from_up, from_down), 1)\n",
    "        else:\n",
    "            x = from_up + from_down\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        return x\n",
    "    \n",
    "class UNet(nn.Module):\n",
    "    \"\"\" `UNet` class is based on https://arxiv.org/abs/1505.04597\n",
    "    The U-Net is a convolutional encoder-decoder neural network.\n",
    "    Contextual spatial information (from the decoding,\n",
    "    expansive pathway) about an input tensor is merged with\n",
    "    information representing the localization of details\n",
    "    (from the encoding, compressive pathway).\n",
    "    Modifications to the original paper:\n",
    "    (1) padding is used in 3x3 convolutions to prevent loss\n",
    "        of border pixels\n",
    "    (2) merging outputs does not require cropping due to (1)\n",
    "    (3) residual connections can be used by specifying\n",
    "        UNet(merge_mode='add')\n",
    "    (4) if non-parametric upsampling is used in the decoder\n",
    "        pathway (specified by upmode='upsample'), then an\n",
    "        additional 1x1 2d convolution occurs after upsampling\n",
    "        to reduce channel dimensionality by a factor of 2.\n",
    "        This channel halving happens with the convolution in\n",
    "        the tranpose convolution (specified by upmode='transpose')\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes, in_channels=1, depth=5,\n",
    "                 start_filts=64, up_mode='transpose',\n",
    "                 merge_mode='concat'):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            in_channels: int, number of channels in the input tensor.\n",
    "                Default is 3 for RGB images.\n",
    "            depth: int, number of MaxPools in the U-Net.\n",
    "            start_filts: int, number of convolutional filters for the\n",
    "                first conv.\n",
    "            up_mode: string, type of upconvolution. Choices: 'transpose'\n",
    "                for transpose convolution or 'upsample' for nearest neighbour\n",
    "                upsampling.\n",
    "        \"\"\"\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        if up_mode in ('transpose', 'upsample'):\n",
    "            self.up_mode = up_mode\n",
    "        else:\n",
    "            raise ValueError(\"\\\"{}\\\" is not a valid mode for \"\n",
    "                             \"upsampling. Only \\\"transpose\\\" and \"\n",
    "                             \"\\\"upsample\\\" are allowed.\".format(up_mode))\n",
    "\n",
    "        if merge_mode in ('concat', 'add'):\n",
    "            self.merge_mode = merge_mode\n",
    "        else:\n",
    "            raise ValueError(\"\\\"{}\\\" is not a valid mode for\"\n",
    "                             \"merging up and down paths. \"\n",
    "                             \"Only \\\"concat\\\" and \"\n",
    "                             \"\\\"add\\\" are allowed.\".format(up_mode))\n",
    "\n",
    "        # NOTE: up_mode 'upsample' is incompatible with merge_mode 'add'\n",
    "        if self.up_mode == 'upsample' and self.merge_mode == 'add':\n",
    "            raise ValueError(\"up_mode \\\"upsample\\\" is incompatible \"\n",
    "                             \"with merge_mode \\\"add\\\" at the moment \"\n",
    "                             \"because it doesn't make sense to use \"\n",
    "                             \"nearest neighbour to reduce \"\n",
    "                             \"depth channels (by half).\")\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.in_channels = in_channels\n",
    "        self.start_filts = start_filts\n",
    "        self.depth = depth\n",
    "\n",
    "        self.down_convs = []\n",
    "        self.up_convs = []\n",
    "\n",
    "        # create the encoder pathway and add to a list\n",
    "        for i in range(depth):\n",
    "            ins = self.in_channels if i == 0 else outs\n",
    "            outs = self.start_filts*(2**i)\n",
    "            pooling = True if i < depth-1 else False\n",
    "\n",
    "            down_conv = DownConv(ins, outs, pooling=pooling)\n",
    "            self.down_convs.append(down_conv)\n",
    "\n",
    "        # create the decoder pathway and add to a list\n",
    "        # - careful! decoding only requires depth-1 blocks\n",
    "        for i in range(depth-1):\n",
    "            ins = outs\n",
    "            outs = ins // 2\n",
    "            up_conv = UpConv(ins, outs, up_mode=up_mode,\n",
    "                merge_mode=merge_mode)\n",
    "            self.up_convs.append(up_conv)\n",
    "\n",
    "        self.conv_final = conv1x1(outs, self.num_classes)\n",
    "\n",
    "        # add the list of modules to current module\n",
    "        self.down_convs = nn.ModuleList(self.down_convs)\n",
    "        self.up_convs = nn.ModuleList(self.up_convs)\n",
    "\n",
    "        self.reset_params()\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.xavier_normal(m.weight)\n",
    "            nn.init.constant(m.bias, 0)\n",
    "\n",
    "\n",
    "    def reset_params(self):\n",
    "        for i, m in enumerate(self.modules()):\n",
    "            self.weight_init(m)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_outs = []\n",
    "\n",
    "        # encoder pathway, save outputs for merging\n",
    "        for i, module in enumerate(self.down_convs):\n",
    "            x, before_pool = module(x)\n",
    "            encoder_outs.append(before_pool)\n",
    "\n",
    "        for i, module in enumerate(self.up_convs):\n",
    "            before_pool = encoder_outs[-(i+2)]\n",
    "            x = module(before_pool, x)\n",
    "\n",
    "        # No softmax is used. This means you need to use\n",
    "        # nn.CrossEntropyLoss is your training script,\n",
    "        # as this module includes a softmax already.\n",
    "        x = self.conv_final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, trainloader, testloader, optimizer, epochs):\n",
    "    model.to(device)\n",
    "    steps = 0\n",
    "    running_loss = 0\n",
    "    running_iou = 0\n",
    "    print_every = 100\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in trainloader:\n",
    "\n",
    "            steps += 1\n",
    "            # Move input and label tensors to the default device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model.forward(inputs)\n",
    "            loss = bce_dice_loss(torch.sigmoid(outputs), labels.reshape(-1, 224, 224).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss\n",
    "            running_iou += my_iou_metric(torch.sigmoid(outputs), labels.reshape(-1, 224, 224).float())\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                test_loss = 0\n",
    "                iou = 0\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in testloader:\n",
    "                        inputs, labels = inputs.to(device), labels.to(device)\n",
    "                        outputs = model.forward(inputs)\n",
    "                        \n",
    "                        test_loss += bce_dice_loss(torch.sigmoid(outputs), labels.reshape(-1, 224, 224).float())\n",
    "                        \n",
    "                        iou += my_iou_metric(torch.sigmoid(outputs), labels.reshape(-1, 224, 224).float())\n",
    "\n",
    "                print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                      f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                      f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                      f\"Train IOU: {running_iou/print_every:.3f}.. \"\n",
    "                      f\"Test IOU: {iou/len(testloader):.3f}.. \")\n",
    " \n",
    "                running_loss = 0\n",
    "                running_iou = 0\n",
    "                   \n",
    "                model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: \n",
      "\n",
      "Preparing the dataset: \n",
      "\n",
      "Train the model: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:198: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:199: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50.. Train loss: 1.678.. Test loss: 1.674.. Train IOU: 0.006.. Test IOU: 0.006.. \n",
      "Epoch 1/50.. Train loss: 1.670.. Test loss: 1.665.. Train IOU: 0.002.. Test IOU: 0.000.. \n",
      "Epoch 2/50.. Train loss: 1.655.. Test loss: 1.641.. Train IOU: 0.001.. Test IOU: 0.005.. \n",
      "Epoch 2/50.. Train loss: 1.291.. Test loss: 1.089.. Train IOU: 0.003.. Test IOU: 0.000.. \n",
      "Epoch 3/50.. Train loss: 1.078.. Test loss: 1.078.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 3/50.. Train loss: 1.077.. Test loss: 1.071.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 3/50.. Train loss: 1.067.. Test loss: 1.064.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 4/50.. Train loss: 1.060.. Test loss: 1.058.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 4/50.. Train loss: 1.052.. Test loss: 1.052.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 5/50.. Train loss: 1.050.. Test loss: 1.044.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 5/50.. Train loss: 1.038.. Test loss: 1.039.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 5/50.. Train loss: 1.036.. Test loss: 1.032.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 6/50.. Train loss: 1.029.. Test loss: 1.027.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 6/50.. Train loss: 1.026.. Test loss: 1.022.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 7/50.. Train loss: 1.018.. Test loss: 1.016.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 7/50.. Train loss: 1.016.. Test loss: 1.011.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 7/50.. Train loss: 1.008.. Test loss: 1.007.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 8/50.. Train loss: 1.005.. Test loss: 1.005.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 8/50.. Train loss: 1.003.. Test loss: 1.003.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 9/50.. Train loss: 1.005.. Test loss: 1.003.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 9/50.. Train loss: 1.001.. Test loss: 1.003.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 9/50.. Train loss: 1.001.. Test loss: 1.001.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 10/50.. Train loss: 1.003.. Test loss: 1.005.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 10/50.. Train loss: 0.998.. Test loss: 0.999.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 11/50.. Train loss: 0.997.. Test loss: 0.999.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 11/50.. Train loss: 0.996.. Test loss: 0.998.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 11/50.. Train loss: 0.997.. Test loss: 0.998.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 12/50.. Train loss: 0.993.. Test loss: 0.999.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 12/50.. Train loss: 0.998.. Test loss: 0.998.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 13/50.. Train loss: 0.997.. Test loss: 0.995.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 13/50.. Train loss: 0.994.. Test loss: 0.996.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 13/50.. Train loss: 0.993.. Test loss: 0.996.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 14/50.. Train loss: 0.988.. Test loss: 0.998.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 14/50.. Train loss: 0.994.. Test loss: 0.993.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 15/50.. Train loss: 0.991.. Test loss: 0.995.. Train IOU: 0.000.. Test IOU: 0.000.. \n",
      "Epoch 15/50.. Train loss: 0.989.. Test loss: 0.994.. Train IOU: 0.006.. Test IOU: 0.011.. \n",
      "Epoch 15/50.. Train loss: 0.991.. Test loss: 0.994.. Train IOU: 0.178.. Test IOU: 0.422.. \n",
      "Epoch 16/50.. Train loss: 0.991.. Test loss: 0.995.. Train IOU: 0.432.. Test IOU: 0.344.. \n",
      "Epoch 16/50.. Train loss: 0.987.. Test loss: 0.993.. Train IOU: 0.419.. Test IOU: 0.398.. \n",
      "Epoch 17/50.. Train loss: 0.989.. Test loss: 0.992.. Train IOU: 0.455.. Test IOU: 0.471.. \n",
      "Epoch 17/50.. Train loss: 0.987.. Test loss: 0.991.. Train IOU: 0.451.. Test IOU: 0.471.. \n",
      "Epoch 18/50.. Train loss: 0.987.. Test loss: 0.993.. Train IOU: 0.414.. Test IOU: 0.454.. \n",
      "Epoch 18/50.. Train loss: 0.989.. Test loss: 0.990.. Train IOU: 0.473.. Test IOU: 0.457.. \n",
      "Epoch 18/50.. Train loss: 0.983.. Test loss: 0.991.. Train IOU: 0.395.. Test IOU: 0.463.. \n",
      "Epoch 19/50.. Train loss: 0.982.. Test loss: 0.986.. Train IOU: 0.413.. Test IOU: 0.442.. \n",
      "Epoch 19/50.. Train loss: 0.986.. Test loss: 0.990.. Train IOU: 0.386.. Test IOU: 0.299.. \n",
      "Epoch 20/50.. Train loss: 0.986.. Test loss: 0.990.. Train IOU: 0.351.. Test IOU: 0.400.. \n",
      "Epoch 20/50.. Train loss: 0.978.. Test loss: 0.986.. Train IOU: 0.370.. Test IOU: 0.355.. \n",
      "Epoch 20/50.. Train loss: 0.988.. Test loss: 0.987.. Train IOU: 0.330.. Test IOU: 0.403.. \n",
      "Epoch 21/50.. Train loss: 0.986.. Test loss: 0.987.. Train IOU: 0.340.. Test IOU: 0.362.. \n",
      "Epoch 21/50.. Train loss: 0.983.. Test loss: 0.986.. Train IOU: 0.358.. Test IOU: 0.345.. \n",
      "Epoch 22/50.. Train loss: 0.979.. Test loss: 0.984.. Train IOU: 0.341.. Test IOU: 0.353.. \n",
      "Epoch 22/50.. Train loss: 0.987.. Test loss: 0.987.. Train IOU: 0.341.. Test IOU: 0.391.. \n",
      "Epoch 22/50.. Train loss: 0.980.. Test loss: 0.987.. Train IOU: 0.304.. Test IOU: 0.293.. \n",
      "Epoch 23/50.. Train loss: 0.978.. Test loss: 0.985.. Train IOU: 0.303.. Test IOU: 0.273.. \n",
      "Epoch 23/50.. Train loss: 0.983.. Test loss: 0.984.. Train IOU: 0.275.. Test IOU: 0.255.. \n",
      "Epoch 24/50.. Train loss: 0.976.. Test loss: 0.984.. Train IOU: 0.263.. Test IOU: 0.257.. \n",
      "Epoch 24/50.. Train loss: 0.982.. Test loss: 0.983.. Train IOU: 0.209.. Test IOU: 0.239.. \n",
      "Epoch 24/50.. Train loss: 0.982.. Test loss: 0.987.. Train IOU: 0.212.. Test IOU: 0.167.. \n",
      "Epoch 25/50.. Train loss: 0.981.. Test loss: 0.982.. Train IOU: 0.183.. Test IOU: 0.150.. \n",
      "Epoch 25/50.. Train loss: 0.979.. Test loss: 0.987.. Train IOU: 0.166.. Test IOU: 0.246.. \n",
      "Epoch 26/50.. Train loss: 0.977.. Test loss: 0.981.. Train IOU: 0.164.. Test IOU: 0.144.. \n",
      "Epoch 26/50.. Train loss: 0.977.. Test loss: 0.984.. Train IOU: 0.157.. Test IOU: 0.128.. \n",
      "Epoch 26/50.. Train loss: 0.975.. Test loss: 0.981.. Train IOU: 0.127.. Test IOU: 0.117.. \n",
      "Epoch 27/50.. Train loss: 0.978.. Test loss: 0.983.. Train IOU: 0.133.. Test IOU: 0.060.. \n",
      "Epoch 27/50.. Train loss: 0.976.. Test loss: 0.977.. Train IOU: 0.118.. Test IOU: 0.180.. \n",
      "Epoch 28/50.. Train loss: 0.977.. Test loss: 0.984.. Train IOU: 0.113.. Test IOU: 0.097.. \n",
      "Epoch 28/50.. Train loss: 0.972.. Test loss: 0.987.. Train IOU: 0.100.. Test IOU: 0.074.. \n",
      "Epoch 28/50.. Train loss: 0.975.. Test loss: 0.979.. Train IOU: 0.105.. Test IOU: 0.083.. \n",
      "Epoch 29/50.. Train loss: 0.977.. Test loss: 0.983.. Train IOU: 0.105.. Test IOU: 0.170.. \n",
      "Epoch 29/50.. Train loss: 0.974.. Test loss: 0.978.. Train IOU: 0.086.. Test IOU: 0.100.. \n",
      "Epoch 30/50.. Train loss: 0.973.. Test loss: 0.978.. Train IOU: 0.099.. Test IOU: 0.141.. \n",
      "Epoch 30/50.. Train loss: 0.977.. Test loss: 0.982.. Train IOU: 0.104.. Test IOU: 0.176.. \n",
      "Epoch 30/50.. Train loss: 0.970.. Test loss: 0.981.. Train IOU: 0.068.. Test IOU: 0.131.. \n",
      "Epoch 31/50.. Train loss: 0.972.. Test loss: 0.979.. Train IOU: 0.071.. Test IOU: 0.095.. \n",
      "Epoch 31/50.. Train loss: 0.972.. Test loss: 0.981.. Train IOU: 0.076.. Test IOU: 0.024.. \n",
      "Epoch 32/50.. Train loss: 0.974.. Test loss: 0.980.. Train IOU: 0.066.. Test IOU: 0.063.. \n",
      "Epoch 32/50.. Train loss: 0.974.. Test loss: 0.975.. Train IOU: 0.095.. Test IOU: 0.102.. \n",
      "Epoch 32/50.. Train loss: 0.965.. Test loss: 0.982.. Train IOU: 0.076.. Test IOU: 0.128.. \n",
      "Epoch 33/50.. Train loss: 0.972.. Test loss: 0.977.. Train IOU: 0.076.. Test IOU: 0.071.. \n",
      "Epoch 33/50.. Train loss: 0.970.. Test loss: 0.982.. Train IOU: 0.088.. Test IOU: 0.168.. \n",
      "Epoch 34/50.. Train loss: 0.964.. Test loss: 0.976.. Train IOU: 0.093.. Test IOU: 0.122.. \n",
      "Epoch 34/50.. Train loss: 0.967.. Test loss: 0.973.. Train IOU: 0.093.. Test IOU: 0.035.. \n",
      "Epoch 35/50.. Train loss: 0.977.. Test loss: 0.976.. Train IOU: 0.062.. Test IOU: 0.109.. \n",
      "Epoch 35/50.. Train loss: 0.967.. Test loss: 0.980.. Train IOU: 0.086.. Test IOU: 0.115.. \n",
      "Epoch 35/50.. Train loss: 0.967.. Test loss: 0.973.. Train IOU: 0.091.. Test IOU: 0.078.. \n",
      "Epoch 36/50.. Train loss: 0.963.. Test loss: 0.971.. Train IOU: 0.096.. Test IOU: 0.128.. \n",
      "Epoch 36/50.. Train loss: 0.964.. Test loss: 0.977.. Train IOU: 0.097.. Test IOU: 0.123.. \n",
      "Epoch 37/50.. Train loss: 0.969.. Test loss: 0.974.. Train IOU: 0.097.. Test IOU: 0.057.. \n",
      "Epoch 37/50.. Train loss: 0.966.. Test loss: 0.975.. Train IOU: 0.083.. Test IOU: 0.118.. \n",
      "Epoch 37/50.. Train loss: 0.965.. Test loss: 0.974.. Train IOU: 0.103.. Test IOU: 0.063.. \n",
      "Epoch 38/50.. Train loss: 0.959.. Test loss: 0.973.. Train IOU: 0.114.. Test IOU: 0.082.. \n",
      "Epoch 38/50.. Train loss: 0.965.. Test loss: 0.970.. Train IOU: 0.103.. Test IOU: 0.120.. \n",
      "Epoch 39/50.. Train loss: 0.967.. Test loss: 0.972.. Train IOU: 0.116.. Test IOU: 0.109.. \n",
      "Epoch 39/50.. Train loss: 0.965.. Test loss: 0.970.. Train IOU: 0.129.. Test IOU: 0.142.. \n",
      "Epoch 39/50.. Train loss: 0.958.. Test loss: 0.975.. Train IOU: 0.135.. Test IOU: 0.179.. \n",
      "Epoch 40/50.. Train loss: 0.962.. Test loss: 0.974.. Train IOU: 0.108.. Test IOU: 0.145.. \n",
      "Epoch 40/50.. Train loss: 0.958.. Test loss: 0.974.. Train IOU: 0.143.. Test IOU: 0.207.. \n",
      "Epoch 41/50.. Train loss: 0.955.. Test loss: 0.971.. Train IOU: 0.142.. Test IOU: 0.192.. \n",
      "Epoch 41/50.. Train loss: 0.950.. Test loss: 0.972.. Train IOU: 0.142.. Test IOU: 0.228.. \n",
      "Epoch 41/50.. Train loss: 0.970.. Test loss: 0.968.. Train IOU: 0.144.. Test IOU: 0.150.. \n",
      "Epoch 42/50.. Train loss: 0.954.. Test loss: 0.964.. Train IOU: 0.158.. Test IOU: 0.101.. \n",
      "Epoch 42/50.. Train loss: 0.955.. Test loss: 0.967.. Train IOU: 0.141.. Test IOU: 0.111.. \n",
      "Epoch 43/50.. Train loss: 0.959.. Test loss: 0.967.. Train IOU: 0.115.. Test IOU: 0.107.. \n",
      "Epoch 43/50.. Train loss: 0.954.. Test loss: 0.968.. Train IOU: 0.167.. Test IOU: 0.119.. \n",
      "Epoch 43/50.. Train loss: 0.952.. Test loss: 0.964.. Train IOU: 0.163.. Test IOU: 0.144.. \n",
      "Epoch 44/50.. Train loss: 0.943.. Test loss: 0.958.. Train IOU: 0.167.. Test IOU: 0.196.. \n",
      "Epoch 44/50.. Train loss: 0.955.. Test loss: 0.961.. Train IOU: 0.157.. Test IOU: 0.201.. \n",
      "Epoch 45/50.. Train loss: 0.939.. Test loss: 0.963.. Train IOU: 0.167.. Test IOU: 0.122.. \n",
      "Epoch 45/50.. Train loss: 0.932.. Test loss: 0.946.. Train IOU: 0.173.. Test IOU: 0.155.. \n",
      "Epoch 45/50.. Train loss: 0.954.. Test loss: 0.953.. Train IOU: 0.154.. Test IOU: 0.154.. \n",
      "Epoch 46/50.. Train loss: 0.937.. Test loss: 0.952.. Train IOU: 0.160.. Test IOU: 0.219.. \n",
      "Epoch 46/50.. Train loss: 0.939.. Test loss: 0.964.. Train IOU: 0.179.. Test IOU: 0.301.. \n",
      "Epoch 47/50.. Train loss: 0.940.. Test loss: 0.946.. Train IOU: 0.177.. Test IOU: 0.203.. \n",
      "Epoch 47/50.. Train loss: 0.938.. Test loss: 0.948.. Train IOU: 0.158.. Test IOU: 0.120.. \n",
      "Epoch 47/50.. Train loss: 0.924.. Test loss: 0.954.. Train IOU: 0.192.. Test IOU: 0.180.. \n",
      "Epoch 48/50.. Train loss: 0.931.. Test loss: 0.953.. Train IOU: 0.196.. Test IOU: 0.146.. \n",
      "Epoch 48/50.. Train loss: 0.933.. Test loss: 0.946.. Train IOU: 0.202.. Test IOU: 0.237.. \n",
      "Epoch 49/50.. Train loss: 0.909.. Test loss: 0.957.. Train IOU: 0.202.. Test IOU: 0.147.. \n",
      "Epoch 49/50.. Train loss: 0.930.. Test loss: 0.952.. Train IOU: 0.203.. Test IOU: 0.122.. \n",
      "Epoch 49/50.. Train loss: 0.929.. Test loss: 0.942.. Train IOU: 0.202.. Test IOU: 0.160.. \n",
      "Epoch 50/50.. Train loss: 0.931.. Test loss: 0.945.. Train IOU: 0.211.. Test IOU: 0.225.. \n",
      "Epoch 50/50.. Train loss: 0.913.. Test loss: 0.938.. Train IOU: 0.206.. Test IOU: 0.308.. \n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print('Loading data: \\n')\n",
    "train_fns, test_fns, df_masks, files_list = load_data()\n",
    "\n",
    "# Training presets\n",
    "batch_size = 16\n",
    "epochs = 50\n",
    "learning_rate = 0.00001\n",
    "test_split = .1\n",
    "\n",
    "original_size = 1024\n",
    "width = 224\n",
    "height = 224\n",
    "\n",
    "# Create dataset and data loader\n",
    "print('Preparing the dataset: \\n')\n",
    "train_ds = PneumothoraxDataset(train_fns, df_masks, files_list, transform=True, size = (height, width), mode = 'train')\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(train_ds)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(test_split * dataset_size))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, sampler=train_sampler, num_workers=4)\n",
    "testloader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, sampler=test_sampler, num_workers=4)\n",
    "\n",
    "valid_ds = PneumothoraxDataset(test_fns, None, None, transform=False, size = (height, width), mode = 'validation')\n",
    "validloader = DataLoader(valid_ds, batch_size=8, shuffle=False, num_workers=1)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Prepare for training: initialize model, loss function, optimizer\n",
    "class param:\n",
    "    unet_depth = 6\n",
    "    unet_start_filters = 8\n",
    "model = UNet(1, depth=param.unet_depth, start_filts=param.unet_start_filters, merge_mode='concat')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Setup device for training\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Train the model\n",
    "print('Train the model: \\n')\n",
    "\n",
    "train_stats_df = pd.DataFrame(columns = ['Epoch','Train loss','Test loss'])\n",
    "train(model, device, trainloader, testloader, optimizer, epochs)\n",
    "\n",
    "# Save the model\n",
    "#print('Save the model: \\n')\n",
    "#filepath = 'simple_unet.pth'\n",
    "#checkpoint = {'state_dict': model.state_dict()}\n",
    "#torch.save(checkpoint, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa66f5728e654165b3f81e4868009e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=173), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "submission = {'ImageId': [], 'EncodedPixels': []}\n",
    "\n",
    "model.eval()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for X, fns in tqdm_notebook(validloader):\n",
    "    X = Variable(X).cuda()\n",
    "    output = model(X)\n",
    "    \n",
    "    for i, fname in enumerate(fns):\n",
    "        mask = torch.sigmoid(output[i].reshape(224,224)).data.cpu().numpy()\n",
    "        mask = binary_opening(mask > 0.9, disk(2))\n",
    "        \n",
    "        im = Image.fromarray(((mask)*255).astype(np.uint8)).resize((original_size,original_size))\n",
    "        im = np.transpose(np.asarray(im))\n",
    "        \n",
    "        submission['EncodedPixels'].append(mask2rle(im, original_size, original_size))\n",
    "        submission['ImageId'].append(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6347.151787519...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6482.151787519...</td>\n",
       "      <td>360603 5 1019 5 1019 5 1019 5 1019 5 1015 14 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.684.1517875164...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6336.151787519...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6736.151787519...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.631.1517875163...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.5842.151787519...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6794.151787520...</td>\n",
       "      <td>313563 5 1019 5 1019 5 1019 5 1019 5 997 4 5 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6360.151787519...</td>\n",
       "      <td>337083 5 5 4 5 4 1001 5 5 4 5 4 1001 5 5 4 5 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.5959.151787519...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                ImageId                                      EncodedPixels\n",
       "602   1.2.276.0.7230010.3.1.4.8323329.6347.151787519...                                                 -1\n",
       "749   1.2.276.0.7230010.3.1.4.8323329.6482.151787519...  360603 5 1019 5 1019 5 1019 5 1019 5 1015 14 1...\n",
       "1142  1.2.276.0.7230010.3.1.4.8323329.684.1517875164...                                                 -1\n",
       "590   1.2.276.0.7230010.3.1.4.8323329.6336.151787519...                                                 -1\n",
       "1028  1.2.276.0.7230010.3.1.4.8323329.6736.151787519...                                                 -1\n",
       "561   1.2.276.0.7230010.3.1.4.8323329.631.1517875163...                                                 -1\n",
       "50    1.2.276.0.7230010.3.1.4.8323329.5842.151787519...                                                 -1\n",
       "1092  1.2.276.0.7230010.3.1.4.8323329.6794.151787520...  313563 5 1019 5 1019 5 1019 5 1019 5 997 4 5 4...\n",
       "617   1.2.276.0.7230010.3.1.4.8323329.6360.151787519...  337083 5 5 4 5 4 1001 5 5 4 5 4 1001 5 5 4 5 4...\n",
       "177   1.2.276.0.7230010.3.1.4.8323329.5959.151787519...                                                 -1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.DataFrame(submission, columns=['ImageId', 'EncodedPixels'])\n",
    "submission_df.loc[submission_df.EncodedPixels=='', 'EncodedPixels'] = '-1'\n",
    "submission_df.to_csv('submission09.csv', index=False)\n",
    "submission_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d80ecc490f4ad1a1108488025be4ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=173), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "for X, fns in tqdm_notebook(validloader):\n",
    "    X = Variable(X).cuda()\n",
    "    output = model(X)\n",
    "    \n",
    "    for i, fname in enumerate(fns):\n",
    "        mask = torch.sigmoid(output[i].reshape(224,224)).data.cpu().numpy()\n",
    "        mask = binary_opening(mask > 0.5, disk(2))\n",
    "        \n",
    "        im = Image.fromarray(((mask)*255).astype(np.uint8)).resize((original_size,original_size))\n",
    "        im = np.transpose(np.asarray(im))\n",
    "        \n",
    "        submission['EncodedPixels'].append(mask2rle(im, original_size, original_size))\n",
    "        submission['ImageId'].append(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6807.151787520...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6198.151787519...</td>\n",
       "      <td>637097 5 4 5 4 5 1001 5 4 5 4 5 1001 5 4 5 4 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6940.151787520...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6767.151787520...</td>\n",
       "      <td>595099 5 1019 5 1019 5 1019 5 987 5 5 4 5 4 5 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2410</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6740.151787519...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6575.151787519...</td>\n",
       "      <td>300183 9 1015 9 1015 9 1015 9 1006 27 997 27 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6678.151787519...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.600.1517875163...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6659.151787519...</td>\n",
       "      <td>641175 9 1015 9 1015 9 1015 9 1015 9 1010 19 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6749.151787519...</td>\n",
       "      <td>374930 5 1019 5 1019 5 1019 5 1015 13 1011 13 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                ImageId                                      EncodedPixels\n",
       "1106  1.2.276.0.7230010.3.1.4.8323329.6807.151787520...                                                 -1\n",
       "439   1.2.276.0.7230010.3.1.4.8323329.6198.151787519...  637097 5 4 5 4 5 1001 5 4 5 4 5 1001 5 4 5 4 5...\n",
       "1253  1.2.276.0.7230010.3.1.4.8323329.6940.151787520...                                                 -1\n",
       "1062  1.2.276.0.7230010.3.1.4.8323329.6767.151787520...  595099 5 1019 5 1019 5 1019 5 987 5 5 4 5 4 5 ...\n",
       "2410  1.2.276.0.7230010.3.1.4.8323329.6740.151787519...                                                 -1\n",
       "2228  1.2.276.0.7230010.3.1.4.8323329.6575.151787519...  300183 9 1015 9 1015 9 1015 9 1006 27 997 27 9...\n",
       "964   1.2.276.0.7230010.3.1.4.8323329.6678.151787519...                                                 -1\n",
       "222   1.2.276.0.7230010.3.1.4.8323329.600.1517875163...                                                 -1\n",
       "943   1.2.276.0.7230010.3.1.4.8323329.6659.151787519...  641175 9 1015 9 1015 9 1015 9 1015 9 1010 19 1...\n",
       "2419  1.2.276.0.7230010.3.1.4.8323329.6749.151787519...  374930 5 1019 5 1019 5 1019 5 1015 13 1011 13 ..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.DataFrame(submission, columns=['ImageId', 'EncodedPixels'])\n",
    "submission_df.loc[submission_df.EncodedPixels=='', 'EncodedPixels'] = '-1'\n",
    "submission_df.to_csv('submission05.csv', index=False)\n",
    "submission_df.sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "08d80ecc490f4ad1a1108488025be4ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.4.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.4.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_62a29fc7e0ae42e1811cc24ae4cffabf",
        "IPY_MODEL_82703a7441a44bbe91f4de7e25cf51c8"
       ],
       "layout": "IPY_MODEL_8d43fb34f8be434c9d39fa4123aa2711"
      }
     },
     "0cd5a8d001dc45c3a99e7e780b957947": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.4.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.1.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "120f396fb0a046f3a30d04dc3118b706": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.4.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.1.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "26fb7697e93f4e3b9065702eba3ea1f3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.1.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.1.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "299e98a736eb4784bd4d1847ae9b8321": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.4.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.1.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "30bca634557f486f9bd1194025d91cc8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.1.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.1.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4bd9871c097949b0979eb42e09a2c71f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.1.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.1.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "62a29fc7e0ae42e1811cc24ae4cffabf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.4.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.4.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_26fb7697e93f4e3b9065702eba3ea1f3",
       "max": 173,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_cf75e03114424462903ac1f84d3a92ee",
       "value": 173
      }
     },
     "82703a7441a44bbe91f4de7e25cf51c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.4.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.4.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4bd9871c097949b0979eb42e09a2c71f",
       "placeholder": "",
       "style": "IPY_MODEL_0cd5a8d001dc45c3a99e7e780b957947",
       "value": "100% 173/173 [11:10&lt;00:00,  2.83s/it]"
      }
     },
     "8d43fb34f8be434c9d39fa4123aa2711": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.1.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.1.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8d577d3f233349af8fcea452cf2bccc1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.1.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.1.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "951a7146ddd6471ab9624337769a139e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.4.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.4.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e2537651bb49445aa9eed588df199fd8",
       "placeholder": "",
       "style": "IPY_MODEL_120f396fb0a046f3a30d04dc3118b706",
       "value": "100% 173/173 [11:12&lt;00:00,  2.96s/it]"
      }
     },
     "c3c36d690ab843d3a1d1a9beea53bae9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.4.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.4.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8d577d3f233349af8fcea452cf2bccc1",
       "max": 173,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_299e98a736eb4784bd4d1847ae9b8321",
       "value": 173
      }
     },
     "cf75e03114424462903ac1f84d3a92ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.4.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.1.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e2537651bb49445aa9eed588df199fd8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.1.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.1.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fa66f5728e654165b3f81e4868009e18": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.4.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.4.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c3c36d690ab843d3a1d1a9beea53bae9",
        "IPY_MODEL_951a7146ddd6471ab9624337769a139e"
       ],
       "layout": "IPY_MODEL_30bca634557f486f9bd1194025d91cc8"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
